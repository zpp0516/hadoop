# Hive安装配置

## 1. Hive介绍

**Hive的用途**

- 方便对文件及数据的元数据进行管理，提供统一的元数据管理方式

- 提供更加简单的方式来访问大规模的数据集，使用SQL语言进行数据分析

**metadata概念**

- hdfs的元数据保存在namenode里，hive的元数据要放在数据库里，它是一个类似于表的格式，方便后面在做SQL转化的时候使用，用SQL语句可以直接查询访问
- metadata包含用Hive创建的database、table等的元信息

- metadata存储在关系型数据库中，如Derby、MySQL等

**metadata作用**

- 客户端连接metastore服务，metastore再去连接数据库来存取元数据

- 有了metastore服务，就可以有多个客户端同时连接，而且这些客户端不需要知道数据库的用户名和密码，只需要连接metastore 服务即可

**Hive的metadata支持本地存储（本地derby、本地MySQL）和远程存储（远程访问MySQL）**

- **内嵌模式 Embedded**：hive服务和metastore服务运行在同一个进程中，Derby也运行在该进程中

  使用Derby数据库来存储元数据，不需要额外起Metastore服务。

  缺点：每启动一个会内嵌一个metastore服务

- **本地模式 Local**：采用外部数据库来存储元数据，hive服务和metastore服务运行在同一个进程中，数据库是单独的进程，数据库通过本地或远程连接

- **远程模式 Remote**：hive和metastore在单独的进程中，可以是不同的节点，数据库本地或远程访问

  每个client通过配置文件里的配置连接到该metastore服务

**Hive在使用过程中是使用SQL语句来进行数据分析，由SQL语句到具体的任务执行还需要经过解释器，编译器，优化器，执行器四部分才能完成**

- 解释器：调用语法解释器和语义分析器将SQL语句转换成对应的可执行的java代码或者业务代码

- 编译器：将对应的java代码转换成字节码文件或者jar包
- 优化器：从SQL语句到java代码的解析转化过程中需要调用优化器，进行相关策略优化，实现最优的查询性能
- 执行器：当业务代码转换完成后，需要上传到MapReduce的集群中执行

## 2 . Hive安装

**Remote Metastore Server 比较适合真实的生产环境，故本文采用此模式进行Hive的安装**

**其中，master安装hive server，slave1安装mysql，slave2、slave3安装 hive client**

解压Hive，移动至Hadoop文件夹下

```
tar -xvf apache-hive-2.3.7-bin.tar.gz -C ../hadoop
mv apache-hive-2.3.7-bin/ hive-2.3.7
```

添加Hive至系统环境变量

```
vi /etc/profile
```

末尾添加以下代码

```
export HIVE_HOME=/usr/hadoop/hive-2.3.7
export PATH=$HIVE_HOME/bin:$PATH
```

生效配置

```
source /etc/profile
```

在hdfs中创建hive目录，并修改当前所属用户组具有写的权限

```
hadoop fs -mkdir /tmp
hadoop fs -mkdir /hive
hadoop fs -mkdir /hive/warehouse  
hadoop fs -chmod g+w /tmp
hadoop fs -chmod g+w /hive/warehouse
```

进入 /usr/hadoop/hive-2.3.7/conf 目录

```
cp hive-default.xml.template hive-site.xml
cp hive-env.sh.template hive-env.sh
```

修改 hive-site.xml 文件，查询  **${system:java.io.tmpdir}** 、**${system:user.name} **并修改以下value值

```
<property>
    <name>hive.exec.local.scratchdir</name>
    <value/>
    <description>Local scratch space for Hive jobs</description>
</property>

<!-- Hive的struct集合类型 -->
<property>
    <name>hive.querylog.location</name>
    <value>/usr/hadoop/hive-2.3.7/logs/root_query_logs</value>
    <description>Location of Hive run time structured log file</description>
</property>
 
<property>
    <name>hive.server2.logging.operation.log.location</name>
    <value>/usr/hadoop/hive-2.3.7/logs/root_operation_logs</value>
    <description>如果启用了日志记录功能，则存储操作日志的顶级目录</description>
</property>

<!-- 官网暂没找到该详细解释 -->
<property>
    <name>hive.downloaded.resources.dir</name>
    <value>/usr/hadoop/hive-2.3.7/tmp/${hive.session.id}_resources</value>
    <description>Temporary local directory for added resources in the remote file system.	  </description>
</property>
```

server端hive-site.xml的配置

```
<property>
	<name>javax.jdo.option.ConnectionURL</name>
	<value>jdbc:mysql://slave1:3306/hive?createDatabaseIfNotExist=true&amp;characterEncoding=UTF-8&amp;useSSL=false</value>
</property>

<property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.jdbc.Driver</value>
</property>

<property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>yoseng</value>
</property>

<property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>Yoseng123@</value>
</property>

<property>
    <name>hive.metastore.warehouse.dir</name>
    <value>hdfs://master:8020/hive/warehouse</value>
    <description>数据仓库存储位置</description>
</property>
```

修改 hive-log4j2.properties文件

```
property.hive.log.dir = /usr/hadoop/hive-2.3.7/logs/${sys:user.name}
```

修改 hive-env.sh 文件

```
HADOOP_HOME=/usr/hadoop/hadoop-2.10.1
```

从清华大学镜像站下载驱动jar包

https://mirrors.tuna.tsinghua.edu.cn/mysql/downloads/Connector-J/

复制到 /usr/hadoop/hive-2.3.7/lib目录中

```
cp mysql-connector-java-5.1.49.jar  /usr/hadoop/hive-2.3.7/lib
```

发送hive和环境配置到slave2、slave3上

```
scp -r hive-2.3.7 slave2:/usr/hadoop
scp /etc/profile slave2:/etc/profile
source /etc/profile

scp -r hive-2.3.7 slave3:/usr/hadoop
scp /etc/profile slave3:/etc/profile
source /etc/profile
```

修改client上的hive-site.xml

```
<property>
    <name>hive.metastore.warehouse.dir</name>
    <value>hdfs://master:8020/hive/warehouse</value>
</property>

<property>
	<name>hive.metastore.uris</name>
	<value>thrift://master:9083</value>
	<description>客户端利用thrift协议通过metastoreServer访问元数据库</description>
</property>
```

在server上，执行初始化（执行一次即可）

```
schematool -dbType mysql -initSchema
```

> 下面显示初始化成功，如提示失败，可能已经进行过初始化，删除数据库即可
>

```
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hadoop/hive-2.3.7/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hadoop/hadoop-2.10.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Metastore connection URL:	 jdbc:mysql://slave1:3306/hive?createDatabaseIfNotExist=true&characterEncoding=UTF-8&useSSL=false
Metastore Connection Driver :	 com.mysql.jdbc.Driver
Metastore connection User:	 yoseng
Starting metastore schema initialization to 2.3.0
Initialization script hive-schema-2.3.0.mysql.sql
Initialization script completed
schemaTool completed
```

在server上启动hive service服务，&代表可以继续输入

```
hive --service metastore &
```

分别在client上启动hive

```
hive
```

  当使用HQL进行操作时，可在 “数据库 hive” 中查看元信息



## 3. Beeline

Hive客户端工具后续将使用Beeline 替代HiveCLI(Hive command line interface)，是一种新的命令行客户端工具，它是基于SQLLine CLI的JDBC客户端

Beeline支持嵌入模式(embedded mode)和远程模式(remote mode)。在嵌入式模式下，运行嵌入式的Hive(类似Hive CLI)，而远程模式可以通过Thrift连接到独立的HiveServer2进程上

在server端，启动beeline server

```
hiveserver2 &
```

client端，启动beeline

```
# 使用anonymous登录
beeline -u jdbc:hive2://master:10000/default
# 使用root登录 
beeline -u jdbc:hive2://master:10000/default -n root
```

beeline登录成功

```
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hadoop/hive-2.3.7/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hadoop/hadoop-2.10.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://master:10000/default
Connected to: Apache Hive (version 2.3.7)
Driver: Hive JDBC (version 2.3.7)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Beeline version 2.3.7 by Apache Hive
0: jdbc:hive2://master:10000/default> 
```

### Beeline Tips：

若出现以下类似错误

```
Failed to open new session: java.lang.RuntimeException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.authorize.AuthorizationException): User: root is not allowed to impersonate root (state=08S01,code=0)
```

需要修改hadoop的core-site.xml文件，添加root用户权限

```
<property>
    <name>hadoop.proxyuser.root.hosts</name>
    <value>*</value>
</property>
<property>
    <name>hadoop.proxyuser.root.groups</name>
    <value>*</value>
</property>
```


## 1. 虚拟机配置
### 1.1 安装CentOS系统

不建议安装CentOS最新版本，安装Centos后修改虚拟机名称为master

注：本文使用VMWare进行配置，若使用VirtualBox配置时，除虚拟机网络配置略有不同外，其他一致。

### 1.2 网络连接介绍
1.桥接模式：虚拟机和物理机连的是同一个网络，虚拟机和物理机是并列关系，地位是相当的。无论是虚拟系统还是真实系统，只要在同一个网段下，相互之间就能ping通。

2.NAT模式：物理机会充当一个“路由器”的角色，虚拟机要想上网，必须经过物理机，那物理机如果不能上网，虚拟机也就不能上网了。不需要进行任何其他的配置，只需要物理机能访问互联网即可。虚拟系统只能和设置虚拟机的主机之间双向访问，无法访问同一网段下其他真实主机。

3.仅主机模式：相当于拿一根网线直连了物理机和虚拟机。所有的虚拟系统是可以相互通信的，但虚拟系统和真实的网络是被隔离开。

### 1.3 虚拟机网络配置
1.在VMWare中打开虚拟网络编辑器，选择VMnet8(NAT)模式，点击NAT设置，配置网关地址(可选择默认值)。 
2.打开控制面板，网络中心，更改适配器，打开VMnet8的属性，配置TCP/IPv4属性。 
3.网关地址与VMWare一致，不要配置已被占用的ip地址。 
4.登录CentOS系统，进入etc/sysconfig/network-scripts中，编辑NAT网卡配置文件。  

	vi ifcfg-ens33 

5.配置以下变量

	BOOTPROTO=static       #关闭DHCP，可以不做，不影响
	ONBOOT=yes 		       #开机启动
	IPADDR=192.168.85.5   #该虚拟机的ip地址
	GATEWAY=192.168.85.2  #网关地址 
	DNS1=192.168.85.2     #DNS可根据自己网络进行配置

### 1.4 重启网卡，网络配置生效
    service network restart  

或  

    systemctl restart network

### 1.5 网络验证

CentOS下查看ip地址：

    ip a

Windows下查看ip地址（运行cmd）：

    ipconfig

若以下操作正确，网络配置成功

- 虚拟机 ping 网关
- 虚拟机 ping 物理主机
- 物理主机 ping 虚拟机
- 虚拟机 ping 百度（若ping不通外网地址，可在上步骤的网络配置文件中，修改其他DNS1地址）

### 1.6 关闭CentOS防火墙
分布式集群中，各个节点之间的通信会受到防火墙的阻碍，因此关闭防火墙（安全问题由专业软件在外围实现防火墙功能，统一管理）

    systemctl stop firewalld.service 

禁止防火墙开机启动  

    systemctl disable firewalld.service 

若出现网络问题，查看网络配置文件是否错误

    vi /etc/sysconfig/network-scripts/ifcfg-ens33


### 1.7 安装XShell、XFtp

XShell与XFtp为付费软件，可在英文官方网站下载免费教育版（中文官网无此版本）

安装成功后，新建连接，输入要连接的虚拟机master ip地址，输入用户名、密码进行连接

登陆成功后，使用XShell代替虚拟机界面进行Shell操作

## 2. 基础环境配置
### 2.1 切换用户至root用户 

    su root

### 2.2 配置时钟同步
在线安装ntpdate，使用阿里云ntp服务器同步时间，date命令查看当前时间

    yum install ntpdate 
    ntpdate ntp.aliyun.com
    date 

若无法连接外网，可离线安装ntpdate ，ntpdate下载地址： [https://pkgs.org/](https://pkgs.org/)  

    rpm -ivh 'ntpdate包的路径' 
    ntpdate ntp.aliyun.com
    date

### 2.3 配置主机名
在网络中能够唯一标识主机，和ip地址一样，可通过ip地址和网络主机名访问这台主机，作用：简化、方便。

修改主机名：

    hostnamectl set-hostname master

查看修改后的主机名：

    hostname

### 2.4 配置hosts列表
hosts列表作用是让集群中的每台服务器彼此都知道对方的主机名和ip地址

    vi /etc/hosts

添加主机ip和主机名

    192.168.253.5 master

验证，ping ip地址和主机名，结果相同无区别

	ping 192.168.85.5
	ping master

### 2.5 安装Java环境
创建个人资料目录，java目录

    mkdir /usr/yoseng
    mkdir /usr/java
    mkdir /usr/hadoop

使用XFtp复制java安装包至yoseng目录下，解压，移动至java目录下

    tar -zxvf jdk-8u241-linux-x64.tar.gz
    mv jdk1.8.0_241 /usr/java/jdk1.8.0_241

进入系统配置文件

	vi /etc/profile

文件最后面添加以下两行

    export JAVA_HOME=/usr/java/jdk1.8.0_241
    export PATH=$JAVA_HOME/bin:$PATH

使配置生效

    source /etc/profile
    java -version

### 2.6 安装Hadoop环境
使用XFtp上传hadoop安装包至yoseng文件夹下，解压Hadoop安装包，并移动至新的文件夹中

	tar -zxvf hadoop-2.10.0-src.tar.gz 
	mv hadoop-2.10.0  /usr/hadoop/hadoop-2.10.0

配置Hadoop环境变量

```
vi /etc/profile
```

在配置文件最后添加以下两行

	export HADOOP_HOME=/usr/hadoop/hadoop-2.10.0
	export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin

使hadoop配置生效，并进行验证

    source /etc/profile
    hadoop version
    whereis hdfs

无错误信息表示hadoop已成功加入到CentOS系统环境中

### 2.7 将hadoop与java绑定(很多同学会忘记此步骤)

设置hadoop配置文件

    cd /usr/hadoop/hadoop-2.10.0/etc/hadoop
    vi hadoop-env.sh

找到下面这行代码：

	export JAVA_HOME=${JAVA_HOME}

将这行代码修改为

	export JAVA_HOME=/usr/java/jdk1.8.0_241

## 3. 配置Hadoop

### 3.1 Hadoop核心文件配置

进入hadoop的etc文件夹，配置core-site.xml文件，新增以下内容

	<configuration>
	    <!--指定文件系统的入口地址，可以为主机名或ip -->
	    <!--端口号默认为8020 -->
	    <property>
	        <name>fs.defaultFS</name>
	        <value>hdfs://master:8020</value>
	    </property>
	    <!--指定hadoop的临时工作存目录-->
	    <property>
	        <name>hadoop.tmp.dir</name>
	        <value>/usr/hadoop/tmp</value>
	    </property>
	</configuration>

配置yarn-env.sh文件，找到该行：

```
# export JAVA_HOME=/home/y/libexec/jdk1.6.0/
```

修改为：

	export JAVA_HOME=/usr/java/jdk1.8.0_241

配置hdfs-site.xml文件，新增以下内容：

	<configuration>
	    <!--指定hdfs备份数量，小于等于从节点数目-->
	    <property>
	        <name>dfs.replication</name>
	        <value>3</value>
	    </property>
			
	  <!--  自定义hdfs中namenode的存储位置-->
	  <!--  <property>-->
	  <!--      <name>dfs.namenode.name.dir</name>-->
	  <!--      <value>file:/usr/hadoop/dfs/name</value>-->
	  <!--  </property>-->
	  <!--  自定义hdfs中datanode的存储位置-->
	  <!--  <property>-->
	  <!--      <name>dfs.datanode.data.dir</name>-->
	  <!--      <value>file:/usr/hadoop/dfs/data</value>-->
	  <!--</property>-->
	</configuration>

配置mapred-site.xml文件，通过cp命令生成不带后缀 `template` 的文件

	cp mapred-site.xml.template mapred-site.xml

编辑mapred-site.xml文件，新增以下内容：

	<configuration>
	    <!--hadoop的MapReduce程序运行在YARN上-->
	    <!--默认值为local-->
	    <property>
	        <name>mapreduce.framework.name</name>
	        <value>yarn</value>
	    </property>
	</configuration>

配置yarn-site.xml文件

	<configuration>
	    <property>
	        <name>yarn.resourcemanager.hostname</name>
	        <value>master</value>
	    </property>     
	    <!--nomenodeManager获取数据的方式是shuffle-->
	    <property>
	        <name>yarn.nodemanager.aux-services</name>
	        <value>mapreduce_shuffle</value>
	    </property>  
	</configuration>

修改slaves文件，删除原有内容，新增即将要建立的三个虚拟机的hostname

```
slave1
slave2
slave3
```

### 3.2 克隆多台slave机

使用master镜像克隆3台虚拟机(创建完整克隆)，名称分别为slave1、slave2、slave3，根据电脑配置情况可以自由设置数量，以下步骤与上方执行过程相同。

- 修改每个slave的主机名，方法同2.3

- 进入etc/sysconfig/network-scripts中，修改每台slave机的ip地址 ，方法同1.3

- 修改master和每个slave机的hosts文件，方法同2.4，将以下代码更新到etc/hosts文件中

  ```
  192.168.253.5 master
  192.168.253.6 slave1
  192.168.253.7 slave2
  192.168.253.8 slave3
  ```

### 3.3 可选---同步hadoop配置（仅当master与slave配置不同时使用）

 将master机上的hadoop文件夹发送给三台slave机

	scp -r /usr/hadoop slave1:/usr/hadoop 
	scp -r /usr/hadoop slave2:/usr/hadoop 
	scp -r /usr/hadoop slave3:/usr/hadoop 

## 4. 配置SSH登录

### 4.1 生成公钥私钥

在master和每台slave上，使用rsa算法产生公钥和私钥（安装过程中，使用“Enter”键确定）

    ssh-keygen -t rsa

查看生成的私钥id_rsa和公钥id_rsa.pub

	cd /root/.ssh/
	ls

### 4.2 发送公钥 

在master上创建一个大家通用的公钥authorized_keys，修改authorized_keys权限，并将这个公钥发送给每个slave

	cat id_rsa.pub >> authorized_keys
	chmod 644 authorized_keys
	systemctl restart sshd.service
	scp /root/.ssh/authorized_keys slave1:/root/.ssh
	scp /root/.ssh/authorized_keys slave2:/root/.ssh
	scp /root/.ssh/authorized_keys slave3:/root/.ssh

### 4.3 Linux文件权限介绍

> 此处为知识介绍，非hadoop配置步骤

- 1-3位数字代表文件所有者的权限
- 4-6位数字代表同组用户的权限
- 7-9位数字代表其他用户的权限
- 读取的权限等于4，用r表示
- 写入的权限等于2，用w表示
- 执行的权限等于1，用x表示

	444 r--r--r--  
	600 rw-------  
	644 rw-r--r--  
	666 rw-rw-rw-  
	700 rwx------  
	744 rwxr--r--  
	755 rwxr-xr-x  
	777 rwxrwxrwx  

### 4.4 验证SSH

ssh登录检验，不需要密码即可登录路径从'~/.ssh '变成'~'，登出为exit

	ssh master
	ssh slave1
	exit
	ssh slave2
	exit
	ssh slave3
	exit

注：只实现了master到slave单向免登陆！！！


## 5. 准备运行hadoop
### 5.1 格式化HDFS
在master机上，进入hadoop下的bin文件夹，运行以下代码：

	hdfs namenode -format

> 注意：只需格式化一次！多次格式化会导致NameNode和DataNode的集群ID值不匹配，需要在格式化前删除NameNode，DataNode、日志等文件夹。

### 5.2 启动hadoop
进入hadoop中的sbin文件夹下，运行：

	start-dfs.sh
	start-yarn.sh

### 5.3 查看hadoop进程

	jps

### 5.4 通过web端访问hadoop

查看NameNode、DataNode：    
[http://192.168.253.5:50070](192.168.233.4:50070)  
查看SecondaryNameNode信息：  
[http://192.168.253.5:50090](192.168.233.4:50090)  
查看YARN界面：  
[http://192.168.253.5:8088](192.168.233.4:8088)